"""åˆ†å±‚å…±è¯†ç½‘ç»œæ„å»º"""

import networkx as nx
import numpy as np
import json
from collections import defaultdict
from community import best_partition, community_louvain
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.spatial.distance import squareform

from analysis_config import AnalysisConfig
from similarity import MultiModalSimilarity
from feature_engine import ThreeDFeatureEngine


class HierarchicalConsensusBuilder:
    """åˆ†å±‚å…±è¯†ç½‘ç»œæ„å»ºå™¨"""

    def __init__(self):
        self.consensus_params = AnalysisConfig.consensus_params
        self.similarity_calculator = MultiModalSimilarity()

    def build_intra_cancer_consensus(self, cancer_samples):
        """æ„å»ºç™Œç—‡å†…éƒ¨å…±è¯†ç½‘ç»œ (CSMs)"""
        print(f"æ„å»ºç™Œç—‡å†…éƒ¨å…±è¯†ç½‘ç»œï¼Œæ ·æœ¬æ•°: {len(cancer_samples)}")

        # ä¸ºæ‰€æœ‰èšç±»æ„å»ºä¸‰ç»´ç‰¹å¾
        all_clusters = self._extract_clusters_with_features(cancer_samples)

        if not all_clusters:
            return {}, nx.Graph()

        # æŠŠèšç±»åˆ—è¡¨è½¬æˆ {cluster_id: cluster_info} å­—å…¸
        cluster_dict = {}
        for cluster in all_clusters:
            cluster_id = cluster.get("cluster_id")
            if cluster_id:
                cluster_dict[cluster_id] = cluster

        # æ„å»ºç›¸ä¼¼åº¦ç½‘ç»œ
        G = nx.Graph()

        # æ·»åŠ èŠ‚ç‚¹
        for cluster_id, cluster_info in cluster_dict.items():
            G.add_node(cluster_id, **cluster_info)

        # è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ·»åŠ è¾¹
        cluster_ids = list(cluster_dict.keys())
        edges_added = 0

        for i in range(len(cluster_ids)):
            cluster_i = cluster_ids[i]
            features_i = cluster_dict[cluster_i]['3d_features']
            sample_i = cluster_i.split('_cluster_')[0]

            for j in range(i + 1, len(cluster_ids)):
                cluster_j = cluster_ids[j]
                features_j = cluster_dict[cluster_j]['3d_features']
                sample_j = cluster_j.split('_cluster_')[0]

                # åªè®¡ç®—è·¨æ ·æœ¬çš„è¿æ¥
                if sample_i != sample_j:
                    # è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦
                    similarity = self.similarity_calculator.calc_comprehensive_similarity(
                        features_i, features_j, mode="CSMs"
                    )

                    # åº”ç”¨ç™Œç—‡å†…éƒ¨é˜ˆå€¼
                    if similarity >= self.consensus_params['intra_cancer_threshold']:
                        G.add_edge(cluster_i, cluster_j, weight=similarity)
                        edges_added += 1

        print(f"ç™Œç—‡å†…éƒ¨ç½‘ç»œ: {G.number_of_nodes()} èŠ‚ç‚¹, {edges_added} è¾¹")

        # ç¤¾åŒºæ£€æµ‹è¯†åˆ«CSMs
        cancer_type = cancer_samples[0].get('cancer_type', 'Unknown') if cancer_samples else 'Unknown'
        csm_clusters = self._detect_robust_structures(G, cancer_samples, cancer_type)

        return csm_clusters, G

    def build_pan_cancer_consensus(self, all_csms):
        """æ„å»ºæ³›ç™Œå…±è¯†ç½‘ç»œ (MPs) - ä¿®å¤ç‰¹å¾ç»Ÿä¸€é—®é¢˜"""
        print("æ„å»ºæ³›ç™Œå…±è¯†ç½‘ç»œ...")

        if not all_csms:
            return {}, nx.Graph()

        # åˆå¹¶æ‰€æœ‰CSMs
        all_structures = {}
        for cancer_type, csms_info in all_csms.items():
            structures = csms_info.get('structures', {})
            for csm_id, csm_info in structures.items():
                pan_id = f"{cancer_type}_{csm_id}"
                all_structures[pan_id] = csm_info

        if not all_structures:
            print("è­¦å‘Šï¼šæ²¡æœ‰å¯åˆå¹¶çš„CSMç»“æ„")
            return {}, nx.Graph()

        # æ„å»ºæ³›ç™Œç½‘ç»œ
        G = nx.Graph()
        edges_added = 0

        # æ·»åŠ èŠ‚ç‚¹ - ä¿®å¤ç‰¹å¾ç»Ÿä¸€é—®é¢˜
        for struct_id, struct_info in all_structures.items():
            if not isinstance(struct_info, dict):
                print(f"è·³è¿‡æ— æ•ˆç»“æ„ {struct_id}ï¼ˆéå­—å…¸ç±»å‹ï¼‰")
                continue

            # ç»Ÿä¸€å¤„ç†3Dç‰¹å¾
            node_attributes = struct_info.copy()
            raw_3d_features = struct_info.get('3d_features', {})

            # ä¿®å¤ï¼šç»Ÿä¸€ç‰¹å¾è¡¨ç¤ºï¼Œç¡®ä¿æ˜¯å­—å…¸
            if isinstance(raw_3d_features, list) and raw_3d_features:
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆåº”è¯¥æ˜¯å­—å…¸ï¼‰
                node_attributes['3d_features'] = raw_3d_features[0]
            elif isinstance(raw_3d_features, dict):
                # å·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                node_attributes['3d_features'] = raw_3d_features
            else:
                # å…¶ä»–æƒ…å†µè®¾ä¸ºç©ºå­—å…¸
                print(f"è­¦å‘Šï¼šç»“æ„ {struct_id} çš„3Dç‰¹å¾æ ¼å¼å¼‚å¸¸: {type(raw_3d_features)}")
                node_attributes['3d_features'] = {}

            G.add_node(struct_id, **node_attributes)

        # è®¡ç®—è·¨ç™Œç—‡ç›¸ä¼¼åº¦
        struct_ids = list(all_structures.keys())
        total_pairs = len(struct_ids) * (len(struct_ids) - 1) // 2
        print(f"è®¡ç®— {total_pairs} å¯¹è·¨ç™Œç—‡CSMçš„ç›¸ä¼¼åº¦...")

        valid_pairs = 0
        similarity_values = []

        for i in range(len(struct_ids)):
            struct_i = struct_ids[i]
            node_data_i = G.nodes[struct_i]
            features_i = node_data_i.get('3d_features', {})

            if not isinstance(features_i, dict) or not features_i:
                continue

            cancer_i = struct_i.split('_')[0]

            for j in range(i + 1, len(struct_ids)):
                struct_j = struct_ids[j]
                node_data_j = G.nodes[struct_j]
                features_j = node_data_j.get('3d_features', {})

                if not isinstance(features_j, dict) or not features_j:
                    continue

                cancer_j = struct_j.split('_')[0]

                # åªè®¡ç®—ä¸åŒç™Œç—‡ç±»å‹é—´çš„ç›¸ä¼¼åº¦
                if cancer_i != cancer_j:
                    valid_pairs += 1
                    try:
                        similarity = self.similarity_calculator.calc_comprehensive_similarity(
                            features_i, features_j, mode="MPs"
                        )
                        similarity_values.append(similarity)

                        # åº”ç”¨æ³›ç™Œé˜ˆå€¼
                        threshold = self.consensus_params.get('pan_cancer_threshold', 0.01)
                        if similarity >= threshold:
                            G.add_edge(struct_i, struct_j, weight=similarity)
                            edges_added += 1

                    except Exception as e:
                        print(f"è®¡ç®— {struct_i} å’Œ {struct_j} ç›¸ä¼¼åº¦æ—¶å‡ºé”™: {str(e)}")
                        continue

        # åˆ†æç›¸ä¼¼åº¦åˆ†å¸ƒ
        if similarity_values:
            similarity_array = np.array(similarity_values)
            print(f"ç›¸ä¼¼åº¦ç»Ÿè®¡: å‡å€¼={similarity_array.mean():.3f}, æ ‡å‡†å·®={similarity_array.std():.3f}")
            print(f"ç›¸ä¼¼åº¦èŒƒå›´: [{similarity_array.min():.3f}, {similarity_array.max():.3f}]")
            print(
                f"é˜ˆå€¼={self.consensus_params.get('pan_cancer_threshold', 0.01):.3f}æ—¶ï¼Œ{np.sum(similarity_array >= self.consensus_params.get('pan_cancer_threshold', 0.01))}/{len(similarity_array)} å¯¹æ»¡è¶³æ¡ä»¶")

        print(f"æœ‰æ•ˆç‰¹å¾å¯¹: {valid_pairs}, æ»¡è¶³é˜ˆå€¼çš„è¾¹: {edges_added}")
        print(f"æ³›ç™Œç½‘ç»œ: {G.number_of_nodes()} èŠ‚ç‚¹, {edges_added} è¾¹")

        # è¯†åˆ«æ³›ç™Œå…ƒç¨‹åº (MPs)
        mp_clusters = self._detect_pan_cancer_structures(G)

        return mp_clusters, G

    def _extract_clusters_with_features(self, cancer_samples):
        """æå–ç™Œç—‡æ ·æœ¬çš„èšç±»åŠç‰¹å¾"""
        all_clusters = []

        for sample in cancer_samples:
            sample_id = sample["sample_id"]
            print(f"   å¤„ç†æ ·æœ¬: {sample_id}")

            # åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹
            feature_engine = ThreeDFeatureEngine(sample)
            # æ„å»ºè¯¥æ ·æœ¬æ‰€æœ‰èšç±»çš„ä¸‰ç»´ç‰¹å¾
            sample_cluster_features = feature_engine.build_all_clusters_3d_features()

            # æŠŠåˆ†æ•£çš„ç‰¹å¾æ•´åˆåˆ°è¯¥å­—æ®µä¸‹
            for cluster_feat in sample_cluster_features:
                # æ•´åˆä¸‰ä¸ªç»´åº¦ç‰¹å¾ä¸º '3d_features'
                cluster_feat['3d_features'] = {
                    'transcript': cluster_feat['transcript_feature'],
                    'cell_context': cluster_feat['cell_context_feature'],
                    'functional': cluster_feat['functional_feature']
                }
                all_clusters.append(cluster_feat)

        print(f"âœ… æå–åˆ° {len(all_clusters)} ä¸ªèšç±»ç‰¹å¾")
        return all_clusters

    def _detect_robust_structures(self, graph, samples, cancer_type):
        """æ£€æµ‹ç¨³å¥çš„ç™Œç—‡å†…éƒ¨å…±è¯†ç»“æ„(CSMs) - ä½¿ç”¨èšåˆç‰¹å¾"""
        sample_count = len(samples)
        min_coverage = max(2, int(sample_count * self.consensus_params.get('min_sample_coverage', 0.4)))
        robust_communities = {}

        try:
            # Louvainç¤¾åŒºæ£€æµ‹
            partition = community_louvain.best_partition(graph, resolution=self.consensus_params.get('resolution', 0.5))
            communities = {}
            for node, comm_id in partition.items():
                if comm_id not in communities:
                    communities[comm_id] = []
                communities[comm_id].append(node)
        except Exception as e:
            print(f"âš ï¸ {cancer_type} ç¤¾åŒºæ£€æµ‹å¤±è´¥ï¼Œé™çº§ä¸ºè¿é€šç»„ä»¶: {str(e)[:50]}")
            connected_components = list(nx.connected_components(graph))
            communities = {i: list(comp) for i, comp in enumerate(connected_components)}

        # éå†ç¤¾åŒºç­›é€‰ç¨³å¥ç»“æ„
        for comm_id, nodes in communities.items():
            # è¿‡æ»¤è¿‡å°ç»“æ„
            if len(nodes) < self.consensus_params.get('min_structure_size', 2):
                continue

            covered_samples = set()
            community_features_3d = []  # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„3Dç‰¹å¾

            # æå–æ ·æœ¬è¦†ç›–+3Dç‰¹å¾
            for node in nodes:
                sample_id = node.split('_cluster_')[0] if '_cluster_' in node else node
                covered_samples.add(sample_id)

                # æå–3Dç‰¹å¾
                if node in graph.nodes:
                    node_data = graph.nodes[node]
                    node_3d = node_data.get('3d_features', {})
                    if isinstance(node_3d, dict) and node_3d:
                        community_features_3d.append(node_3d)

            # è¿‡æ»¤è¦†ç›–ç‡ä¸è¶³çš„ç»“æ„
            if len(covered_samples) < min_coverage:
                continue

            coverage_ratio = len(covered_samples) / sample_count
            csm_id = f"{cancer_type}_{comm_id}"

            # ğŸ¯ ä½¿ç”¨èšåˆç‰¹å¾è€Œä¸æ˜¯ç¬¬ä¸€ä¸ªç‰¹å¾
            aggregated_3d = self._aggregate_csm_features(community_features_3d)

            # ä¿å­˜CSM
            robust_communities[csm_id] = {
                'id': csm_id,
                'cancer_type': cancer_type,
                'nodes': nodes,
                'size': len(nodes),
                'sample_coverage': len(covered_samples),
                'coverage_ratio': coverage_ratio,
                'sample_ids': list(covered_samples),
                '3d_features': aggregated_3d,  # ğŸ¯ ä½¿ç”¨èšåˆç‰¹å¾
                'node_features': community_features_3d,  # ä¿ç•™åŸå§‹èŠ‚ç‚¹ç‰¹å¾ç”¨äºè°ƒè¯•
                'has_valid_3d': bool(aggregated_3d)
            }

        print(f"âœ… {cancer_type}: å‘ç° {len(robust_communities)} ä¸ªç¨³å¥CSMs")
        return robust_communities

    def _aggregate_csm_features(self, community_features_3d):
        """èšåˆCSMå†…æ‰€æœ‰èšç±»çš„ä¸‰ç»´ç‰¹å¾"""
        if not community_features_3d:
            return {}

        # 1. èšåˆè½¬å½•ç‰¹å¾ - åˆå¹¶æ‰€æœ‰ç‰¹å¼‚æ€§åŸºå› ï¼ŒæŒ‰å¹³å‡SpecScoreæ’åº
        all_transcript_genes = {}
        gene_counts = {}

        for feat in community_features_3d:
            transcript_feat = feat.get('transcript', {})
            specific_genes = transcript_feat.get('specific_genes', [])

            for gene, score in specific_genes:
                if gene not in all_transcript_genes:
                    all_transcript_genes[gene] = 0.0
                    gene_counts[gene] = 0
                all_transcript_genes[gene] += score
                gene_counts[gene] += 1

        # è®¡ç®—å¹³å‡SpecScore
        avg_transcript_genes = [
            (gene, all_transcript_genes[gene] / gene_counts[gene])
            for gene in all_transcript_genes
        ]
        # æŒ‰å¹³å‡SpecScoreé™åºæ’åˆ—
        avg_transcript_genes.sort(key=lambda x: x[1], reverse=True)

        # 2. èšåˆç»†èƒå¾®ç¯å¢ƒç‰¹å¾ - è®¡ç®—å¹³å‡ç»†èƒç±»å‹æ¯”ä¾‹
        all_cell_types = {}
        cell_type_counts = {}

        for feat in community_features_3d:
            cell_context = feat.get('cell_context', {})
            cell_proportions = cell_context.get('cell_type_proportions', {})

            for cell_type, proportion in cell_proportions.items():
                if cell_type not in all_cell_types:
                    all_cell_types[cell_type] = 0.0
                    cell_type_counts[cell_type] = 0
                all_cell_types[cell_type] += proportion
                cell_type_counts[cell_type] += 1

        # è®¡ç®—å¹³å‡æ¯”ä¾‹
        avg_cell_proportions = {
            cell_type: all_cell_types[cell_type] / cell_type_counts[cell_type]
            for cell_type in all_cell_types
        }

        # 3. èšåˆåŠŸèƒ½ç‰¹å¾ - åˆå¹¶æ‰€æœ‰å¯Œé›†é€šè·¯ï¼ŒæŒ‰å¹³å‡på€¼æ’åº
        all_pathways = {}
        pathway_counts = {}

        for feat in community_features_3d:
            functional_feat = feat.get('functional', {})
            pathways = functional_feat.get('enriched_pathways', [])

            for pathway in pathways:
                term = pathway.get('term')
                adj_p = pathway.get('adj_pvalue', 1.0)

                if term not in all_pathways:
                    all_pathways[term] = {
                        'adj_pvalue_sum': 0.0,
                        'count': 0,
                        'source': pathway.get('source', 'unknown')
                    }
                all_pathways[term]['adj_pvalue_sum'] += adj_p
                all_pathways[term]['count'] += 1

        # è®¡ç®—å¹³å‡på€¼ï¼ŒæŒ‰æ˜¾è‘—æ€§æ’åº
        avg_pathways = [
            {
                'term': term,
                'adj_pvalue': all_pathways[term]['adj_pvalue_sum'] / all_pathways[term]['count'],
                'source': all_pathways[term]['source']
            }
            for term in all_pathways
        ]
        avg_pathways.sort(key=lambda x: x['adj_pvalue'])

        return {
            'transcript': {
                'specific_genes': avg_transcript_genes,
                'spec_score_mean': np.mean(
                    [score for _, score in avg_transcript_genes]) if avg_transcript_genes else 0.0,
                'gene_count': len(avg_transcript_genes)
            },
            'cell_context': {
                'cell_type_proportions': avg_cell_proportions,
                'dominance': max(avg_cell_proportions.values()) if avg_cell_proportions else 0.0,
                'evenness': 1 - max(avg_cell_proportions.values()) if avg_cell_proportions else 0.0,
                'cell_type_count': len(avg_cell_proportions)
            },
            'functional': {
                'enriched_pathways': avg_pathways,
                'pathway_count': len(avg_pathways),
                'term_standardized': True
            }
        }

    def _detect_pan_cancer_structures(self, graph):
        """æ£€æµ‹æ³›ç™Œç»“æ„ (MPs) - ä¿®å¤è·ç¦»çŸ©é˜µé—®é¢˜"""
        if graph.number_of_nodes() == 0:
            return {}

        # å½“è¾¹æ•°å¾ˆå°‘æ—¶ï¼Œä½¿ç”¨è¿é€šç»„ä»¶è€Œä¸æ˜¯å±‚æ¬¡èšç±»
        if graph.number_of_edges() < 5:
            print("è¾¹æ•°è¿‡å°‘ï¼Œä½¿ç”¨è¿é€šç»„ä»¶æ£€æµ‹MPs")
            mp_clusters = {}
            for i, component in enumerate(nx.connected_components(graph)):
                nodes = list(component)
                cancer_types = [node.split('_')[0] for node in nodes]
                unique_cancer_types = list(set(cancer_types))
                mp_clusters[i] = {
                    'nodes': nodes,
                    'cancer_types': unique_cancer_types,
                    'cancer_count': len(unique_cancer_types)
                }
            return mp_clusters

        # ä½¿ç”¨å±‚æ¬¡èšç±»è¯†åˆ«MPs
        try:
            # æ„å»ºè·ç¦»çŸ©é˜µ
            nodes = list(graph.nodes())
            n_nodes = len(nodes)

            if n_nodes < 2:
                mp_clusters = {
                    0: {
                        'nodes': nodes,
                        'cancer_types': [node.split('_')[0] for node in nodes],
                        'cancer_count': len(set(node.split('_')[0] for node in nodes))
                    }
                }
                return mp_clusters

            # è®¡ç®—è·ç¦»çŸ©é˜µï¼ˆ1 - ç›¸ä¼¼åº¦ï¼‰
            dist_matrix = np.zeros((n_nodes, n_nodes))  # åˆå§‹åŒ–ä¸ºé›¶
            for i in range(n_nodes):
                for j in range(i + 1, n_nodes):
                    if graph.has_edge(nodes[i], nodes[j]):
                        similarity = graph[nodes[i]][nodes[j]]['weight']
                        dist_matrix[i, j] = 1 - similarity
                        dist_matrix[j, i] = 1 - similarity
                    else:
                        dist_matrix[i, j] = 1.0  # æ²¡æœ‰è¿æ¥æ—¶è·ç¦»ä¸º1
                        dist_matrix[j, i] = 1.0

            # ç¡®ä¿å¯¹è§’çº¿ä¸ºé›¶
            np.fill_diagonal(dist_matrix, 0.0)

            # æ£€æŸ¥è·ç¦»çŸ©é˜µæ˜¯å¦æœ‰æ•ˆ
            if np.any(np.isnan(dist_matrix)) or np.any(np.isinf(dist_matrix)):
                print("è·ç¦»çŸ©é˜µåŒ…å«æ— æ•ˆå€¼ï¼Œä½¿ç”¨è¿é€šç»„ä»¶")
                raise ValueError("Invalid distance matrix")

            # å±‚æ¬¡èšç±»
            condensed_dist = squareform(dist_matrix)
            linkage_matrix = linkage(condensed_dist, method='ward')

            # åŠ¨æ€ç¡®å®šèšç±»æ•°é‡
            if n_nodes <= 5:
                t_criterion = 0.8
            else:
                t_criterion = 0.5

            clusters = fcluster(linkage_matrix, t=t_criterion, criterion='distance')

            # æŒ‰èšç±»åˆ†ç»„
            mp_clusters = defaultdict(list)
            for node_idx, cluster_id in enumerate(clusters):
                mp_clusters[cluster_id - 1].append(nodes[node_idx])

            # è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼
            final_mp_clusters = {}
            for mp_id, nodes_list in mp_clusters.items():
                cancer_types = [node.split('_')[0] for node in nodes_list]
                unique_cancer_types = list(set(cancer_types))
                cancer_count = len(unique_cancer_types)

                final_mp_clusters[mp_id] = {
                    'nodes': nodes_list,
                    'cancer_types': unique_cancer_types,
                    'cancer_count': cancer_count
                }

            print(f"å±‚æ¬¡èšç±»æˆåŠŸ: å°† {n_nodes} ä¸ªèŠ‚ç‚¹åˆ†ä¸º {len(final_mp_clusters)} ä¸ªMPs")
            return final_mp_clusters

        except Exception as e:
            print(f"å±‚æ¬¡èšç±»å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨è¿é€šç»„ä»¶")
            # å¤±è´¥æ—¶ä½¿ç”¨è¿é€šç»„ä»¶ä½œä¸ºå¤‡é€‰
            mp_clusters = {}
            for i, component in enumerate(nx.connected_components(graph)):
                nodes = list(component)
                cancer_types = [node.split('_')[0] for node in nodes]
                unique_cancer_types = list(set(cancer_types))
                mp_clusters[i] = {
                    'nodes': nodes,
                    'cancer_types': unique_cancer_types,
                    'cancer_count': len(unique_cancer_types)
                }
            return mp_clusters